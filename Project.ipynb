{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4528d9d3-7912-4dfa-b0b6-491508004b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd119a6-260c-49fc-b486-a3f338386eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./train_data_chatbot.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3214b39-e4d3-4c71-84f5-12b6d5e92187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_question</th>\n",
       "      <th>short_answer</th>\n",
       "      <th>tags</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can an antibiotic through an iv give you a ras...</td>\n",
       "      <td>yes it can even after you have finished the pr...</td>\n",
       "      <td>['rash' 'antibiotic']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>can you test positive from having the hep b va...</td>\n",
       "      <td>test positive for what if you had a hep b vacc...</td>\n",
       "      <td>['hepatitis b']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what are the dietary restrictions for celiac d...</td>\n",
       "      <td>omitting gluten from the diet is the key to co...</td>\n",
       "      <td>['celiac disease']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>can i transmit genital warts seventeen years a...</td>\n",
       "      <td>famotidine pepcid products is in a drug class ...</td>\n",
       "      <td>['wart']</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is all vitamin d the same</td>\n",
       "      <td>hi this means you do not have hepatitis b and ...</td>\n",
       "      <td>['vitamin d']</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      short_question  \\\n",
       "0  can an antibiotic through an iv give you a ras...   \n",
       "1  can you test positive from having the hep b va...   \n",
       "2  what are the dietary restrictions for celiac d...   \n",
       "3  can i transmit genital warts seventeen years a...   \n",
       "4                          is all vitamin d the same   \n",
       "\n",
       "                                        short_answer                   tags  \\\n",
       "0  yes it can even after you have finished the pr...  ['rash' 'antibiotic']   \n",
       "1  test positive for what if you had a hep b vacc...        ['hepatitis b']   \n",
       "2  omitting gluten from the diet is the key to co...     ['celiac disease']   \n",
       "3  famotidine pepcid products is in a drug class ...               ['wart']   \n",
       "4  hi this means you do not have hepatitis b and ...          ['vitamin d']   \n",
       "\n",
       "   label  \n",
       "0    1.0  \n",
       "1    1.0  \n",
       "2    1.0  \n",
       "3   -1.0  \n",
       "4   -1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41300132-0a58-4b66-8e35-da1a7c07f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b13ee4b-1080-41bd-9cb1-ba156dc53212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9c15afb-f9a6-41ff-8e6d-7785795e4f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = data[\"short_question\"].astype(str).tolist()\n",
    "answers = data[\"short_answer\"].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "117574f8-8206-466c-a000-de3aa37ef07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fb37aa7-1fce-46b1-8ae2-98f4f61c5ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_q = [clean_text(text) for text in questions]\n",
    "# Flatten the token lists to get a single list of tokens\n",
    "all_tokens = [token for sublist in cleaned_data_q for token in sublist]\n",
    "cleaned_data_q = [\" \".join(tokens) for tokens in cleaned_data_q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "940a1a6f-79d9-4b52-af5e-e51fda02d711",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_a = [clean_text(text) for text in answers]\n",
    "# Flatten the token lists to get a single list of tokens\n",
    "all_tokens = [token for sublist in cleaned_data_a for token in sublist]\n",
    "cleaned_data_a = [\" \".join(tokens) for tokens in cleaned_data_a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "080dbbcf-9761-49e6-ab2e-54af79da21e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_data_q\n",
    "y = cleaned_data_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6df07bb-99c8-4281-af1e-75c8fc032e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "symp_train, symp_test, y_train, y_test = train_test_split(\n",
    "   X, y, test_size = 0.20, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8824e429-287c-4fa4-8d8c-070451d05b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb2bb6a7-d4ea-4145-be18-e834db1df592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"question\"], examples[\"answer\"], truncation=True, padding=\"max_length\", max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3327d258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vysha\\ADA\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ff04ae35e74bc49b68caa83ce40053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/47603 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./Mistral7B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # or use `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`\n",
    "data_dict = {\"question\": cleaned_data_q, \"answer\": cleaned_data_a}\n",
    "dataset = Dataset.from_dict(data_dict)\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41f910e4-28fc-44ad-8018-b00792a3f8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95567001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3feefbbbde3490dabdb35036192a488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the tokenizer and model from the local directory\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./Mistral7B\" , quantization_config=bnb_config, device_map=\"auto\")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62b462ac-a38d-411b-b8e8-c0cca08a93a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed439580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "project = \"journal-finetune\"\n",
    "base_model_name = \"mistral\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    warmup_steps=2,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=1,\n",
    "    gradient_checkpointing=True,\n",
    "    max_steps=200,\n",
    "    learning_rate=2.5e-3,\n",
    "    bf16=True,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    logging_steps=25,              # When to start reporting loss\n",
    "    logging_dir=\"./logs\",        # Directory for storing logs\n",
    "    save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "    save_steps=25,                # Save checkpoints every 50 steps\n",
    "    eval_strategy=\"steps\", # Evaluate the model every logging step\n",
    "    eval_steps=25,               # Evaluate and save checkpoints every 50 steps\n",
    "    do_eval=True,                # Perform evaluation at the end of training\n",
    "    report_to=\"none\",                   # Disable wandb logging\n",
    "    run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d9ca36f-2ee2-47ab-8d14-721bbe3c4ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "from datetime import datetime\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34832673-5caa-4aca-94dc-7f891cbdaf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accelerator = Accelerator()\n",
    "model = accelerator.prepare_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd2d8cfd-b8ea-45b4-a767-c84aeec59e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset,\n",
    "    args=training_args,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4743daec-bb87-4bf4-ad15-ad5569f70e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vysha\\ADA\\Lib\\site-packages\\torch\\utils\\checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 16:50:15, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>83.762000</td>\n",
       "      <td>88.469246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>77.338400</td>\n",
       "      <td>65.406128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>58.325900</td>\n",
       "      <td>56.152134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>50.988800</td>\n",
       "      <td>48.491367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>41.509300</td>\n",
       "      <td>45.079681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>43.245700</td>\n",
       "      <td>41.103291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>42.875500</td>\n",
       "      <td>38.507347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>32.936300</td>\n",
       "      <td>34.945564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vysha\\ADA\\Lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "C:\\Users\\vysha\\ADA\\Lib\\site-packages\\torch\\utils\\checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "C:\\Users\\vysha\\ADA\\Lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "C:\\Users\\vysha\\ADA\\Lib\\site-packages\\torch\\utils\\checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "C:\\Users\\vysha\\ADA\\Lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "C:\\Users\\vysha\\ADA\\Lib\\site-packages\\torch\\utils\\checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "C:\\Users\\vysha\\ADA\\Lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "C:\\Users\\vysha\\ADA\\Lib\\site-packages\\torch\\utils\\checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "C:\\Users\\vysha\\ADA\\Lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "C:\\Users\\vysha\\ADA\\Lib\\site-packages\\torch\\utils\\checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "C:\\Users\\vysha\\ADA\\Lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "C:\\Users\\vysha\\ADA\\Lib\\site-packages\\torch\\utils\\checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "C:\\Users\\vysha\\ADA\\Lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "C:\\Users\\vysha\\ADA\\Lib\\site-packages\\torch\\utils\\checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "C:\\Users\\vysha\\ADA\\Lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=53.872742614746095, metrics={'train_runtime': 60618.1076, 'train_samples_per_second': 0.007, 'train_steps_per_second': 0.003, 'total_flos': 2211493340774400.0, 'train_loss': 53.872742614746095, 'epoch': 0.008402655239055541})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9053e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vysha\\ADA\\Lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./mistral-finetunedi\\\\tokenizer_config.json',\n",
       " './mistral-finetunedi\\\\special_tokens_map.json',\n",
       " './mistral-finetunedi\\\\tokenizer.json')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./mistral-finetuned\")\n",
    "tokenizer.save_pretrained(\"./mistral-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa3fa8c-a876-4066-a38b-541190b27a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
